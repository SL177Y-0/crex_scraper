# 🏏 Crex Scraper

A **real-time cricket data scraping system** that monitors and extracts **match schedules, detailed match information, live score updates, and more** from [CREX](https://crex.live/fixtures/match-list). 

🔧 **Tech Stack:**  
✅ **Backend:** FastAPI (Python), Celery, PostgreSQL, Redis  
✅ **Frontend:** Next.js (React, TypeScript)  
✅ **Orchestration:** Docker & Docker Compose  
✅ **Data Handling:** Web Scraping, API Integration, Real-time Processing  

---

## 📂 Project Structure

```plaintext
crex_scraper/
├── backend/                         # Backend service (FastAPI, Celery, DB connection, etc.)
│   ├── Dockerfile                   # Builds the backend container image
│   ├── requirements.txt             # Python dependencies (FastAPI, Celery, etc.)
│   ├── main.py                      # FastAPI application entry point
│   ├── scraper.py                   # Web scraping logic for cricket data
│   ├── scheduler.py                 # Celery tasks & scheduler for real-time scraping
│   ├── database.py                  # Database connection and setup (SQLAlchemy)
│   ├── models.py                    # Database models (e.g., Match model)
│   └── utils.py                     # Utility functions (e.g., logging setup)
│
├── frontend/                        # Frontend service (Next.js app)
│   ├── Dockerfile                   # Builds the frontend container image
│   ├── package.json                 # Node.js dependencies and build scripts
│   └── src/
│       ├── pages/                   # Next.js pages
│       │   ├── index.tsx            # Home page: displays match list/dashboard
│       │   └── match/
│       │       └── [id].tsx         # Dynamic match detail page with tabs
│       └── components/              # Reusable React components
│           ├── MatchCard.tsx        # Animated match card component
│           └── LiveScore.tsx        # Live score update component (WebSocket)
│
├── db/                              # Database initialization scripts
│   └── init.sql                     # SQL script to create tables and initialize schema
│
├── docker-compose.yml               # Orchestrates backend, frontend, PostgreSQL, and Redis containers
└── README.md                        # Project documentation and setup instructions
```


## 🚀 Features

✅ Scrape Match Schedules – Automatically fetch upcoming match schedules from CREX.
✅ Detailed Match Data – Extract data from "Match Info," "Squads," "Live," and "Scorecard."
✅ Real-time Updates – Celery tasks trigger scrapes when a match starts, fetching live data.
✅ Interactive UI – A sleek Next.js dashboard with animations and hover effects.
✅ Containerized Deployment – Easily deploy using Docker & Docker Compose.


## ⚙️ Prerequisites
Docker & Docker Compose (Recommended for easy setup)
Git (Optional, for cloning the repository)
Node.js (18+) (For frontend local development if not using Docker)
Python 3.8+ & pip (For backend local development if not using Docker)

                   
## 🛠 Setup Instructions
🔹 1. Clone the Repository (Optional)
bash
Copy
Edit
git clone https://github.com/SL177Y/crex_scraper.git
cd crex_scraper
🔹 2. Build & Start the Containers (Docker)
Run the following command from the project root:

bash
Copy
Edit
docker-compose up --build
                   
This will: ✅ Build the backend (FastAPI) and frontend (Next.js) images.
                   
## ✅ Start the services:

Backend (FastAPI): http://localhost:8000
Frontend (Next.js): http://localhost:3000
PostgreSQL: localhost:5432
Redis: localhost:6379

                   
🔹 3. Verify the Services
Frontend: Open http://localhost:3000 in your browser.
Backend API: Check http://localhost:8000 for the FastAPI welcome page.
Database: Confirm PostgreSQL is running via a client or Docker logs.
Redis: Ensure Redis is running for Celery task management.

                
🔹 4. Database Initialization
If the database needs initialization, run:

bash
Copy
Edit
psql -U user -d matches -f db/init.sql
Replace user and matches with your database credentials from docker-compose.yml.

                   
🔹 5. Stopping the Containers
Press Ctrl + C in the terminal where docker-compose up is running, then execute:

bash
Copy
Edit
docker-compose down
This stops and removes all running containers.

🖥️ Local Development (Without Docker)
➡️ Backend

bash
Copy
Edit
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
By default, FastAPI runs on http://127.0.0.1:8000.

➡️ Frontend

bash
Copy
Edit
cd frontend
npm install
npm run dev
Next.js will start on http://127.0.0.1:3000.

⚠️ If not using Docker, make sure PostgreSQL and Redis are running manually.

